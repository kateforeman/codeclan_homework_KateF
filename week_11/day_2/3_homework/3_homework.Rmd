---
title: "Decision trees homework"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
```


<br>
In this homework we will create a decision tree to see which factors are useful in predicting whether or not a passenger on the titanic will survive.  


Run the code below before you begin: 


```{r, warning = FALSE, message = FALSE}
library(tidyverse) 
library(rpart)
library(rpart.plot)
library(modelr) 
library(caret) 
library(yardstick) 
library(randomForest) 

titanic_set <- read_csv('data/titanic_decision_tree_data.csv')

shuffle_index <- sample(1:nrow(titanic_set))

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]
```

<br>

**Data Dictionary**

  * **sex**: Biological Sex, male or female  
  * **age_status**: adult or child (child defined as under 16)  
  * **class** : Ticket class, 1 = 1st (Upper class), 2 = 2nd (Middle Class), 3 = 3rd (Lower Class)    
  * **port_embarkation**: C = Cherbourg, Q = Queenstown, S = Southampton  
  * **sibsp** : number of siblings / spouses aboard the Titanic   
  * **parch**: number of parents / children aboard the Titanic. Some children travelled only with a nanny, therefore parch=0 for them. 
  * **survived_flag** : did they survive, 0 = No, 1 = Yes  



# MVP 


## Question 1  

<br> 
Cleaning up the data is always the first step. Do the following: 

  * Take only observations which have a `survived` flag (i.e. that aren't missing)  
  * Turn your important variables into factors (sex, survived, pclass, embarkation)  
  * Create an `age_status` variable which groups individuals under (and including) 16 years of age into a category called "child" category and those over 16 into a category called "adult".  
  * Drop the NA  
  * Drop any variables you don't need (`X1`, `passenger_id`, `name`, `ticket`, `far`, `cabin`)  

If you need help doing this, the code is below, but please try it yourself first so you can learn! 

```{r}
titanic_clean <- titanic_set %>% 
  drop_na(survived) %>% 
  mutate(sex = as.factor(sex)) %>% 
  mutate(survived = as.factor(survived)) %>% 
  mutate(pclass = as.factor(pclass)) %>% 
  mutate(embarked = as.factor(embarked)) %>% 
  mutate(age_status = ifelse(age > 16, "adult", "child")) %>% 
  drop_na() %>% 
  select(-c("X1", "passenger_id", "name", "ticket", "fare", "cabin")) 

titanic_clean 
```

## Question 2  


Have a look at your data and create some plots to ensure you know what you're working with before you begin. Write a summary of what you have found in your plots. Which variables do you think might be useful to predict whether or not people are going to die? Knowing this before you start is the best way to have a sanity check that your model is doing a good job.  

```{r}
titanic_clean %>% 
  filter(survived == 1) %>% 
  ggplot(aes(sex, survived, fill = sex)) +  
  geom_col() 
```

```{r}
titanic_clean %>% 
  filter(survived == 1) %>% 
  ggplot(aes(pclass, survived, fill = pclass)) + 
  geom_col() 
```

```{r}
titanic_clean %>% 
  filter(survived == 1) %>% 
  ggplot(aes(age_status, survived, fill = age_status)) + 
  geom_col() 
```
It looks like being female and being in first class could be variables worth 
exploring in the model. 

## Question 3  

<br> 
Now you can start to build your model. Create your testing and training set using an appropriate split. Check you have balanced sets. Write down why you chose the split you did and produce output tables to show whether or not it is balanced. 

```{r}
n_data <- nrow(titanic_clean) 

test_index <- sample(1:n_data, size = n_data * 0.15) 

titanic_survival_test  <- slice(titanic_clean, test_index) 

titanic_survival_train <- slice(titanic_clean, -test_index) 

titanic_survival_test %>%
 janitor::tabyl(survived)  

titanic_survival_train  %>%
 janitor::tabyl(survived) 
```

This 15% and 85% split represented a more similar balance between test and train than a 20% and 80% split. 

<br>
## Question 4      

<br> 
Create your decision tree to try and predict survival probability using an appropriate method, and create a decision tree plot. 

```{r}
titanic_fit <- rpart(
  formula = survived ~ ., 
  data = titanic_survival_train, 
  method = 'class'
)

rpart.plot(titanic_fit, yesno = 2, fallen.leaves = TRUE, faclen = 6, digits = 4) 
```

```{r}
rpart.plot(titanic_fit, yesno = 2, fallen.leaves = TRUE, faclen = 6, digits = 4, type = 4, extra = 101) 
```

<br>

## Question 5    

<br> 
Write down what this tells you, in detail. What variables are important? What does each node tell you? Who has the highest chance of surviving? Who has the lowest? Provide as much detail as you can.    
 
The decision tree model seems to have decided that gender is an important variable in predicting the survival. The survival probability of being a female is 0.94 and for males it's 0.40. It deems the ages of 36.5 and 31.5 important. For males over the age of 36.5 the probability of surviving was 0.29. For those who embarked at Queenstown, the probability of being a male, over 36.25 and surviving is 0.19. For those males, over 36.5 who did not embark there, the probability rate is 0.54, indicating the embarkment at Queenstown is possibly better for the probability of surviving. For males under the age of 31.5 the probability rate of survival is 0.47. The probability of surviving is lower for single children without siblings compared to those with siblings. 

## Question 6     

<br>  
Test and add your predicitons to your data. Create a confusion matrix. Write down in detial what this tells you for this specific dataset.  

```{r} 
titanic_test_predictions <- titanic_survival_test %>%
  add_predictions(titanic_fit, type = 'class') 

titanic_test_predictions %>% 
  select(sex, age, age_status, pclass, embarked, sib_sp) 
```

```{r}
conf_mat <- titanic_test_predictions %>%
              conf_mat(truth = survived, estimate = pred)

conf_mat
```


```{r}
accuracy <- titanic_test_predictions %>%
 accuracy(truth = survived, estimate = pred)

accuracy 

confusion_matrix_detail <- confusionMatrix(titanic_test_predictions$pred, titanic_test_predictions$survived) 

confusion_matrix_detail 
```

This model is not that accurate. The probability of predicting the survival of a person or not is only 0.51 to 1. This is nearly just guessing. The diagonal values are only as follows: 

True Positive - 2 

True Negative - 12 

The higher the values along the main diagonal of the confusion matrix, the better fit the model is. 

The true positive rate is only 0.22 which is pretty dismal. The true negative rate is 0.66 which is definitely better than the true positive rate but overall, this decision tree is not that accurate for predicting the probability of someone surviving on the titanic unfortunately. 

# Extension  

Decision tree algorithms have various parameters that control aspects of the fit. Adjusting the parameters of a model is called "tuning" and it is a key part of more extensive model building and maintenance. In the `rpart` library, you can control the parameters using the `rpart.control()` function. Refer to the vignette for parameters you can control (e.g. depth, minimum number of sample points a node needs to have, minimum number of samples a leaf node must have). See if you can try to tune the parameters and see if you can improve the model over the default value.  